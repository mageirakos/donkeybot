{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetchers Notebook Contents\n",
    "- [How can I create a `Fetcher`?](#How-can-I-create-a-Fetcher-?)\n",
    "- [How can I fetch GitHub issues?  ](#How-can-I-fetch-GitHub-issues?)\n",
    "- [How does Donkeybot fetch Rucio documentation?](#How-does-Donkeybot-Fetch-Rucio-Documentation?)\n",
    "- [How does Donkeybot save the fetched data?](#How-does-Donkeybot-save-the-fetched-data?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scripts `fetch_issues.py`, `fetch_rucio_docs.py` do everything explained here.**  \n",
    "See [scripts](https://github.com/rucio/donkeybot/tree/master/scripts) for source code and run the scripts with the '-h' option for info on the arguments they take.  \n",
    "eg.  \n",
    "\n",
    "`(virt)$ python scripts/fetch_rucio_docs.py -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I create a `Fetcher` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple, use the `FetcherFactory` and just pick the fetcher type \n",
    "- Issue for a GitHub `IssueFetcher`\n",
    "- Rucio Documentation for a `RucioDocsFetcher`   \n",
    "\n",
    "What about the `EmailFetcher` ?\n",
    "- Currently as explained in [How It Works](https://github.com/rucio/donkeybot/blob/master/docs/how_it_works.md) emails are fetched from different scripts run in CERN and not through Donkeybot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.fetcher.factory import FetcherFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a GitHub `IssueFetcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bot.fetcher.issues.IssueFetcher at 0x1b75c30b6c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_fetcher = FetcherFactory.get_fetcher(\"Issue\")\n",
    "issues_fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I fetch GitHub issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need 4 things.\n",
    "- The **repository** whose issues we are fetching\n",
    "- A **GitHub API token**. To generate a GitHub token visit [Personal Access Tokens](https://github.com/settings/tokens) and follow [Creating a Personal Access Token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token).\n",
    "- The **maximum number of pages** the fetcher will look through to fetch issues. (default is 201)\n",
    "- A couple pandas **DataFrames**, one which will hold the issues data and one for the issue comments data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = 'rucio/rucio' # but you can use any in the format user/repo\n",
    "token = \"<YOUR_TOKEN>\"\n",
    "max_pages = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(issues_df, comments_df) = issues_fetcher.fetch(repo=repository, api_token=token, max_pages=max_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting DataFrames will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   issue_id    26 non-null     object\n",
      " 1   title       26 non-null     object\n",
      " 2   state       26 non-null     object\n",
      " 3   creator     26 non-null     object\n",
      " 4   created_at  26 non-null     object\n",
      " 5   comments    26 non-null     object\n",
      " 6   body        26 non-null     object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "issues_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   issue_id    16 non-null     object\n",
      " 1   comment_id  16 non-null     object\n",
      " 2   creator     16 non-null     object\n",
      " 3   created_at  16 non-null     object\n",
      " 4   body        16 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 768.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Donkeybot Fetch Rucio Documentation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same process we followed with the `IssueFetcher` only now the factory will create a `RucioDocsFetcher`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.fetcher.factory import FetcherFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bot.fetcher.docs.RucioDocsFetcher at 0x1b75c43bf48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_fetcher = FetcherFactory.get_fetcher(\"Rucio Documentation\")\n",
    "docs_fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"<YOUR_TOKEN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = docs_fetcher.fetch(api_token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Donkeybot save the fetched data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we need to  \n",
    "**Step 1.** open a connection to our Data Storage  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.database.sqlite import Databae\n",
    "\n",
    "# open the connection\n",
    "db_name = 'data_storage'\n",
    "data_storage = Database(f\"{db_name}.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.** Save the fetched issues and comments data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fetched data\n",
    "issues_fetcher.save(\n",
    "    db=data_storage,\n",
    "    issues_table_name='issues',\n",
    "    comments_table_name='issue_comments',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1.** Alternativerly save the documentation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fetched data\n",
    "docs_fetcher.save(db=data_storage, docs_table_name='docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.** Finally close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the connection\n",
    "data_storage.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative :** If you don't want to use Donkeybot's Data Storage you can use the `save_with_pickle()` and `load_with_pickle()` methods to achieve the same results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
