{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Detector Notebook Contents\n",
    "- [How can I create an AnswerDetector?](#How-can-I-create-an-AnswerDetector?)\n",
    "- [How does the AnswerDetecor work?](#How-does-the-AnswerDetecor-work?)\n",
    "- [So what data is stored for each answer?](#So-what-data-is-stored-for-each-answer?)\n",
    "- [What is the difference between the AnswerDetector and the QAInterface? ](#What-is-the-difference-between-the-AnswerDetector-and-the-QAInterface?)\n",
    "- [How can I create a QAInterface?](#How-can-I-create-a-QAInterface?)\n",
    "- [Can I use the AnswerDetector for my projects?](#Can-I-use-the-AnswerDetector-for-my-projects?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I create an AnswerDetector?\n",
    "\n",
    "It's very simple, just call the constructor!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.answer.detector import AnswerDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bot.answer.detector.AnswerDetector at 0x296561f3d48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_detector = AnswerDetector(model='distilbert-base-cased-distilled-squad',\n",
    "                                 extended_answer_size=30,\n",
    "                                 handle_impossible_answer=True,\n",
    "                                 max_answer_len=20,\n",
    "                                 max_question_len=20,\n",
    "                                 max_seq_len=256,\n",
    "                                 num_answers_to_predict=3,\n",
    "                                 doc_stride=128,\n",
    "                                 device=0)\n",
    "answer_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do all these paremeters mean?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well if you want to go deeper you can always look at the [Source Code](https://github.com/rucio/donkeybot/blob/master/lib/bot/answer/detector.py).   \n",
    "\n",
    "The important parameters for now are : \n",
    "- **model :**  name of the transformer model used for QuestionAnswering.\n",
    "- **num_answers_to_predit :** Number of answers that are predicted for each document that the AnswerDetector is given.    \n",
    "\n",
    "Remember these documents are the ones retrieved by each Search Engine so a lot of answers are predicted until top_k are returned.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the AnswerDetecor work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.** Have a **question**.   \n",
    "\n",
    "**Step 2.** Have some **documents** in which the answer might reside in.    \n",
    "\n",
    "**Step 3.** Make sure those documents are in a pandas **DataFrame** and the context used for answer detection is under the \"context\" column.\n",
    "\n",
    "As of right now there is no option to simply use the AnswerDetector with strings.  \n",
    "For Donkeybot which uses different datasources we decided to utilize pandas DataFrames.  \n",
    "Donkeybot can always be expanded if the functionality is required.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the aim of Donkeybot?\" \n",
    "\n",
    "documents = pd.DataFrame({\n",
    "    \"context\" : [\"\"\"\n",
    "                The aim of the Donkeybot project under GSoC 2020 is to use Natural Language Processing (NLP) \n",
    "                to develop an intelligent bot prototype able to provide satisfying answers to Rucio users \n",
    "                and handle support requests up to a certain level of complexity, \n",
    "                forwarding only the remaining ones to the experts.\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                Different levels of expert support are available for users in case of problems. \n",
    "                When satisfying answers are not found at lower support levels, a request from a user or a group \n",
    "                of users can be escalated to the Rucio support. Due to the vast amount of support requests, \n",
    "                methods to assist the support team in answering these requests are needed.\n",
    "                \"\"\"],\n",
    "    \"col_2\" : [\"first_doc\", \"second_doc\"],\n",
    "    \"col_3\" : [\"other\", \"data\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting answers from 2 document(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = answer_detector.predict(question, documents, top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So asking `What is the aim of Donkeybot?`, providing the above documents and asking for 2 answers gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the aim of Donkeybot?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['answer 1: assist the support team | confidence : 0.44691182870541724',\n",
       " 'answer 2: to use Natural Language Processing (NLP) | confidence : 0.24323081332589425']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(question)\n",
    "[(f\"answer {i+1}: {answer.answer} | confidence : {answer.confidence}\") for i,answer in enumerate(answers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what data is stored for each answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'c3e44f0799b645c9b690f98e4b5e07ea',\n",
       " 'user_question': 'What is the aim of Donkeybot?',\n",
       " 'user_question_id': '2fc28e8f32',\n",
       " 'answer': 'to use Native Language Processing (NLP)',\n",
       " 'start': 69,\n",
       " 'end': 125,\n",
       " 'confidence': 0.24011110691572668,\n",
       " 'extended_answer': 'ot project under GSoC 2020 is to use Native Language Processing (NLP) \\n                to develop an intelligent bot',\n",
       " 'extended_start': 39,\n",
       " 'extended_end': 155,\n",
       " 'model': 'distilbert-base-cased-distilled-squad',\n",
       " 'origin': 'questions',\n",
       " 'created_at': '2020-08-26 18:08:08+00:00',\n",
       " 'label': None,\n",
       " 'metadata': {'col_2': 'first_doc', 'col_3': 'other'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[1].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [How it Works](https://github.com/rucio/donkeybot/blob/master/docs/how_it_works.md) where we cover the same information and explain in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between the AnswerDetector and the QAInterface? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the QAInterface under `brain.py` of Donkeybot, glues together all `SearchEngines` nd the  `AnswerDetector`.   \n",
    "\n",
    "It is the interface used in `ask_donkeybot.py` script. Take a look at the [Source Code](https://github.com/rucio/donkeybot/blob/master/scripts/ask_donkeybot.py) or the [QAInterface example notebook](https://github.com/rucio/donkeybot/blob/master/examples/qa_interface.ipynb) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I create a QAInterface?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that you have correctly created:\n",
    "- `AnswerDetector`\n",
    "- `SearchEngine` \n",
    "- `QuestionSearchEngine` \n",
    "- `FAQSearchEngine`   \n",
    "\n",
    "All correctly.\n",
    "\n",
    "Then simply load the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.brain import QAInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load interface\n",
    "qa_interface = QAInterface(\n",
    "    detector=answer_detector,\n",
    "    question_engine=question_se,\n",
    "    faq_engine=faq_se,\n",
    "    docs_engine=docs_se,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can I use the AnswerDetector for my projects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, but it probably will require some tweaking and if you aren't using Donkeybot for setting up and curating your data then it might not be worth it.   \n",
    "\n",
    "Simply look under the hood and use Transformer pipelines for your needs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
